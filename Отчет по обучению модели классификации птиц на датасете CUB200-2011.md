# Отчет по обучению модели классификации птиц на датасете CUB200-2011

## Обзор проекта

Данный проект посвящен обучению модели глубокого обучения для классификации изображений птиц на основе мелкозернистого датасета CUB200-2011. Для решения задачи используется архитектура EfficientNetV2-S, предобученная на ImageNet, с применением техник трансферного обучения и аугментации данных.

## Архитектура модели

### Базовая модель

*   **Архитектура:** EfficientNetV2-S
*   **Предобученные веса:** ImageNet (`DEFAULT`)

### Модификации

Для адаптации модели к задаче классификации 200 видов птиц был заменен последний слой классификатора:

```python
import torch.nn as nn
# ...
model = efficientnet_v2_s(weights='DEFAULT')
num_classes = 200 # Для CUB200-2011
model.classifier[1] = nn.Linear(in_features=model.classifier[1].in_features, out_features=num_classes, bias=True)
```

*   **Входные признаки классификатора:** 1280
*   **Выходные классы:** 200 (количество видов птиц в CUB200-2011)
*   **Устройство:** CUDA (GPU)

## Датасет и предобработка

### Датасет CUB200-2011

*   **Источник:** Caltech Birds 2011 (CUB-200-2011)
*   **Количество классов:** 200
*   **Исходное разделение:** train/test
*   **Примененное разделение:** Оригинальный train сплит и 90% оригинального test сплита были объединены и затем разделены на новый тренировочный (80%) и валидационный (20%) наборы. Оставшиеся 10% оригинального test сплита использовались для финальной оценки.

### Кастомный класс датасета

Используется кастомный класс `CUB200Dataset` для загрузки изображений и меток из файлов датасета. В ходе отладки было выявлено, что метки классов могут требовать корректировки (вычитание 1) для 0-индексации, необходимой функциям потерь PyTorch.

### Аугментация данных

Применялась разнообразная аугментация для увеличения объема и вариативности тренировочных данных.
В ходе работы использовались разные конфигурации аугментации. Изначально агрессивная аугментация с `TrivialAugmentWide` и `RandomErasing` показала быстрый рост, но приводила к сильному переобучению. В дальнейшем конфигурация была изменена на более умеренную, включающую:

```python
import torchvision.transforms.v2 as T
# ...
train_transforms_aug = T.Compose([
    T.RandomResizedCrop(224, scale=(0.5, 1.0)),
    T.RandomHorizontalFlip(),
    T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.3),
    T.RandomRotation(degrees=30),
    T.ToTensor(),
    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    # Опционально могла использоваться RandomErasing или Cutout
])
```

*   **Цель аугментации:** Увеличение разнообразия тренировочных данных, повышение устойчивости модели, снижение переобучения.

### Предобработка изображений

Для валидационного и тестового наборов данных использовалась стандартная предобработка без аугментации:

```python
preprocessor = T.Compose([
    T.Resize(256), # Часто используется перед CenterCrop для EfficientNet
    T.CenterCrop(224),
    T.ToTensor(),
    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])
```
*   **Параметры нормализации:** Mean=[0.485, 0.456, 0.406], Std=[0.229, 0.224, 0.225] (стандартные для ImageNet).
*   **Размер изображения:** 224x224 пикселей (после обрезки).

## Функции обучения и валидации

### Функция обучения (`train`)

*   Переводит модель в режим обучения (`model.train()`).
*   Итерируется по батчам тренировочных данных.
*   Перемещает данные на GPU.
*   При необходимости корректирует метки классов (`labels = labels - 1`).
*   Обнуляет градиенты (`optimizer.zero_grad()`).
*   Выполняет прямой проход (`model(images)`).
*   Вычисляет потери (`loss_func(outputs, labels)`).
*   Выполняет обратное распространение ошибки (`loss.backward()`).
*   Обновляет веса модели (`optimizer.step()`).
*   Рассчитывает и логирует средние потери и точность за эпоху.
*   Поддерживает опциональное использование Автоматического Смешанного Прецизионного обучения (AMP) с `torch.cuda.amp.GradScaler`.
*   Использует `tqdm` для отображения прогресса и текущих метрик.

### Функция валидации (`valid`)

*   Переводит модель в режим оценки (`model.eval()`).
*   Отключает вычисление градиентов (`@torch.inference_mode()` и `with torch.no_grad():`).
*   Итерируется по батчам валидационных данных.
*   Перемещает данные на GPU.
*   При необходимости корректирует метки классов (`labels = labels - 1`).
*   Выполняет прямой проход (`model(images)`).
*   Получает предсказания.
*   Рассчитывает и возвращает среднюю точность на валидационном наборе.
*   Использует `tqdm` для отображения прогресса и текущей точности.

## Результаты обучения

Процесс обучения демонстрировал устойчивый рост точности как на тренировочном, так и на валидационном наборах данных.

*   **Наблюдения:**
    *   Модель быстро обучалась, показывая значительный рост точности в первые эпохи.
    *   Наблюдалось некоторое переобучение (тренировочная точность была выше валидационной), что ожидаемо для мелкозернистого датасета и мощной модели.
    *   Применение более умеренной аугментации способствовало более стабильному росту валидационной точности.
    *   Использование планировщика темпа обучения `ReduceLROnPlateau` помогало регулировать скорость обучения на основе динамики валидационной точности.

*   **Лучшая достигнутая валидационная точность:** 81.40% (на 30-й эпохе в одном из циклов тренировки).

*   **Финальная точность на тестовом наборе:** 81.27% (при оценке лучшей модели). Этот результат очень близок к лучшей валидационной точности, что свидетельствует о хорошем обобщении модели на невиданные данные.

## Технические детали

*   **Размер изображения:** 224x224 пикселей
*   **Batch size:** 64
*   **Количество эпох:** До 30 в зависимости от запуска
*   **Устройство:** CUDA GPU
*   **Функция потерь:** `torch.nn.CrossEntropyLoss()`
*   **Оптимизатор:** `torch.optim.Adam()` с начальным темпом обучения и весовым расцветом.
    *   Настройки: `lr=1e-4`, `weight_decay=1e-5` (используемые значения могли варьироваться в ходе экспериментов).
*   **Планировщик темпа обучения:** `torch.optim.lr_scheduler.ReduceLROnPlateau`
    *   Параметры: `mode='max'`, `patience=5-10`, `factor=0.1` (параметры могли настраиваться). Снижал темп обучения, когда валидационная точность переставала расти.
*   **Сохранение модели:** Сохранялось состояние (`state_dict`) модели с лучшей валидационной точностью. Путь сохранения указывал на Google Drive.

## Проблемы в процессе работы и решения

1.  **`ImportError: cannot import name 'Caltech_birds2011' from 'torchvision.datasets'`**: Датасет не входит в стандартный torchvision. Решение: использование кастомного `CUB200Dataset` класса для чтения данных из файлов.
2.  **Проблемы со скачиванием данных через TFDS/torchvision (`ValueError`)**: Автоматическая загрузка датасетов (CUB, StanfordCars) не работала из-за проблем с URL/GDrive. Решение: ручная загрузка и распаковка архивов.
3.  **`NameError: name 'CUB_200_2011' is not defined`**: Необходимость полного кастомного класса `Dataset`. Решение: реализация класса `CUB200Dataset` для чтения из локальных файлов.
4.  **`OutOfMemoryError: CUDA out of memory`**: Недостаточно памяти GPU. Решения: уменьшение `batch_size`, уменьшение `num_workers` DataLoader'а, использование `torch.cuda.empty_cache()`, рассмотрение AMP (Автоматическое Смешанное Прецизионное обучение).
5.  **`RuntimeError: device-side assert triggered` во время тренировки/валидации**: Связано с некорректными метками классов (вероятно, не 0-индексированными). Решение: отладка с `CUDA_LAUNCH_BLOCKING=1`, корректировка меток классов (`labels = labels - 1`) в функциях `train` и `valid` после перемещения на устройство, если метки в источнике начинаются с 1.
6.  **Модель не обучается (низкая точность)**: Связано с некорректными трансформациями или LR. Решения: проверка и корректировка цепочки трансформаций, проверка learning rate, визуализация данных после DataLoader.
7.  **`TypeError` при применении аугментации**: Неправильное использование классов трансформаций (передача самого класса вместо экземпляра) или некорректная структура `T.Compose`. Решение: создание экземпляров классов трансформаций, правильная структура `T.Compose`.
8.  **`KeyboardInterrupt` из-за вложенного цикла в `train`**: Ошибка в логике итерации по DataLoader'у. Решение: удаление лишнего внутреннего цикла.
9.  **`RuntimeError: device-side assert triggered` при загрузке весов (`torch.load`)**: Несовпадение структуры модели и загружаемого `state_dict`, вероятно из-за разного количества выходных классов. Решение: убедиться, что `state_dict` сохранен от модели с правильным количеством выходных классов (200).

## Рекомендации по улучшению

*   **Продвинутая аугментация:** Экспериментировать с Mixup, CutMix, или Cutout для дальнейшего снижения переобучения.
*   **Настройка гиперпараметров:** Более тонкая настройка learning rate, weight decay и параметров планировщика.
*   **Ранняя остановка:** Реализовать явную логику ранней остановки на основе валидационной точности с заданным `patience`.
*   **Параметро-эффективное дообучение (PEFT):** Рассмотреть методы типа LoRA или Bias Tuning для более эффективного дообучения и снижения риска переобучения на небольшом датасете.
*   **Детальная оценка:** Провести детальную оценку на тестовом наборе с расчетом Precision, Recall, F1-score для каждого класса, а также матрицу ошибок, чтобы выявить проблемы с конкретными классами.

## Заключение

В результате проведенной работы удалось успешно загрузить, подготовить и обучить модель EfficientNetV2-S на датасете CUB200-2011. Несмотря на ряд возникших в процессе проблем, связанных в основном с особенностями датасета и отладкой процесса обучения, финальная модель достигла точности 81.27% на тестовом наборе, что является хорошим результатом для задачи мелкозернистой классификации. Дальнейшие улучшения могут быть достигнуты за счет применения более продвинутых техник регуляризации и аугментации.